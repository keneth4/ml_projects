{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Megaline: Smart or Ultra\n",
    "\n",
    "The mobile company Megaline is not satisfied seeing many of its customers using legacy plans. They want to develop a model that can analyze customer behavior and recommend one of Megaline's new plans: Smart or Ultra.\n",
    "\n",
    "You have access to behavioral data from subscribers who have already switched to the new plans (from the Data Statistical Analysis course project). For this classification task, you should create a model that chooses the right plan. Since you have already gone through the data processing step, you can jump straight into creating the model.\n",
    "\n",
    "Develop a model with the highest accuracy possible. In this project, the accuracy threshold is 0.75. Use the dataset to check the accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "\n",
    "Each observation in the dataset contains monthly behavior information about a user. The provided information is as follows:\n",
    "\n",
    "- `сalls` — number of calls.\n",
    "- `minutes` — total call duration in minutes.\n",
    "- `messages` — number of text messages.\n",
    "- `mb_used` — Internet traffic used in MB.\n",
    "- `is_ultra` — plan for the current month (Ultra - 1, Smart - 0).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into DataFrames\n",
    "df = pd.read_csv('../datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Print the general/summary information about the DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>56.0</td>\n",
       "      <td>333.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15373.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>34.0</td>\n",
       "      <td>248.65</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12741.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>6.0</td>\n",
       "      <td>36.45</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4617.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>89.0</td>\n",
       "      <td>627.32</td>\n",
       "      <td>88.0</td>\n",
       "      <td>16627.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>67.0</td>\n",
       "      <td>356.05</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19909.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used  is_ultra\n",
       "1330   56.0   333.23       0.0  15373.48         0\n",
       "1749   34.0   248.65      18.0  12741.28         0\n",
       "125     6.0    36.45       7.0   4617.10         0\n",
       "3119   89.0   627.32      88.0  16627.19         0\n",
       "1784   67.0   356.05      48.0  19909.97         0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a random sample of 5 rows from the DataFrame\n",
    "df.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into features and target\n",
    "features = df.drop(\"is_ultra\", axis=1)\n",
    "target = df[\"is_ultra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into training, validation, and test subsets (3:1:1)\n",
    "features_train, features_valid_test, target_train, target_valid_test = train_test_split(features, target, test_size=.4, random_state=12345)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid_test, target_valid_test, test_size=.5, random_state=12345)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the quality of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random seed for the experiments\n",
    "random_state=12345"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of the best model: 3\n",
      "Accuracy of the best model on the validation set: 0.7853810264385692\n"
     ]
    }
   ],
   "source": [
    "# Train several decision tree models with different maximum depths and find the best one\n",
    "best_score = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 50):\n",
    "\tmodel = DecisionTreeClassifier(random_state=random_state, max_depth=depth)\n",
    "\tmodel.fit(features_train, target_train)\n",
    "\tscore = model.score(features_valid, target_valid)\n",
    "\tif score > best_score:\n",
    "\t\tbest_score = score\n",
    "\t\tbest_depth = depth\n",
    "    \n",
    "print(\"Depth of the best model:\", best_depth)\n",
    "print(\"Accuracy of the best model on the validation set:\", best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimators of the best model: 23\n",
      "Accuracy of the best model on the validation set: 0.7947122861586314\n"
     ]
    }
   ],
   "source": [
    "# Train several random forest models with different numbers of estimators and find the best one\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(1, 50):\n",
    "    model = RandomForestClassifier(random_state=random_state, n_estimators=est)\n",
    "    model.fit(features_train, target_train)\n",
    "    score = model.score(features_valid, target_valid)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "\n",
    "print(\"Number of estimators of the best model:\", best_est)\n",
    "print(\"Accuracy of the best model on the validation set:\", best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the logistic regression model on the training set: 0.7510373443983402\n",
      "Accuracy of the logistic regression model on the validation set: 0.7573872472783826\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model and find the accuracy on the validation set\n",
    "model = LogisticRegression(random_state=random_state, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "score_train = model.score(features_train, target_train)\n",
    "score_valid = model.score(features_valid, target_valid)\n",
    "\n",
    "print(\"Accuracy of the logistic regression model on the training set:\", score_train)\n",
    "print(\"Accuracy of the logistic regression model on the validation set:\", score_valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Conclusion\n",
    "\n",
    "Of the 3 different types of classifiers:\n",
    "- The `decision tree` model had the second highest score and the second shortest execution time\n",
    "- The `random forest` model had the highest score and the longest execution time\n",
    "- The `logistic regression` model had the lowest score and the shortest execution time\n",
    "\n",
    "The **`Decision Tree`** model with the hyperparameter `max_depth = 3` will be the chosen model as it has the best balance between score and execution time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the decision tree model on the test set: 0.7791601866251944\n"
     ]
    }
   ],
   "source": [
    "# Train a decision tree model with the maximum depth found earlier and determine the accuracy on the test set\n",
    "model = DecisionTreeClassifier(random_state=random_state, max_depth=best_depth)\n",
    "model.fit(features_train, target_train)\n",
    "score_test = model.score(features_test, target_test)\n",
    "\n",
    "print(\"Accuracy of the decision tree model on the test set:\", score_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier Score: 0.6842923794712286\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy classifier that always predicts the most frequent class\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=random_state)\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "# Calculate the score on the test data\n",
    "dummy_score = dummy.score(features_test, target_test)\n",
    "\n",
    "print(f'Dummy Classifier Score: {dummy_score}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Conclusion\n",
    "\n",
    "- The `Dummy Classifier` model, which always predicts the most frequent class, guesses correctly 68.4% of the time.\n",
    "- The `Decision Tree` model guesses correctly 77.9% of the time. This indicates that the model is learning from the data and making predictions that are significantly better than a model that just guesses the most frequent class.\n",
    "\n",
    "**Note**: The data is imbalanced, as a `Dummy Classifier` on a balanced dataset would have an accuracy of 50%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Conclusion\n",
    "\n",
    "The tested classification models included the `decision tree`, `random forest`, and `logistic regression`. The analysis revealed that:\n",
    "\n",
    "- The `decision tree` model had the second highest score and the second shortest execution time.\n",
    "- The `random forest` model had the highest score and the longest execution time.\n",
    "- The `logistic regression` model had the lowest score and the shortest execution time.\n",
    "\n",
    "The `decision tree` model with the hyperparameter `max_depth = 3` was chosen for its balance between a '`0.779`' score and execution time. This model outperformed the Dummy Classifier, indicating that the model is learning from the data and making predictions that are significantly better than a model that merely guesses the most frequent class.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
